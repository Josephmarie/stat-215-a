{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bc269f-4088-420e-96e7-12eef328c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def clean_data(data_path, remove_feats_after_ct=True, remove_TBI_rows_with_nan=True,threshold=0.5,rm_feats=True,remove_GCS_total_mismatch=True):\n",
    "    # Remove rows with missing values\n",
    "    data = pd.read_csv(\"TBI PUD 10-08-2013.csv\")\n",
    "    data_clean = copy.copy(data)\n",
    "    # change value 92 in column to NaN for the following list of features\n",
    "    list_92 = ['LocLen','SeizOccur','SeizLen','HASeverity','HAStart','VomitNbr','VomitStart','VomitLast','AMSAgitated','AMSSleep','AMSSlow','AMSRepeat','AMSOth','SFxPalpDepress','FontBulg','SFxBasHem','SFxBasOto','SFxBasPer','SFxBasRet','SFxBasRhi','HemaLoc','HemaSize','ClavFace','ClavNeck','ClavFro','ClavOcc','ClavPar','ClavTem','NeuroDMotor','NeuroDSensory','NeuroDCranial','NeuroDReflex','NeuroDOth','OSI','OSIExtremity','OSICut','OSICspine','OSIFlank','OSIAbdomen','OSIPelvis','OSIOth','Drugs','IndAge','IndAmnesia','IndAMS','IndClinSFx','IndHA','IndHema','IndLOC','IndMech','IndNeuroD','IndRqstMD','IndRqstParent','IndRqstTrauma','IndSeiz','IndVomit','IndXraySFx','IndOth','CTSed','CTSedAgitate','CTSedAge','CTSedRqst','CTSedOth','EDCT','PosCT','Finding1','Finding2','Finding3','Finding4','Finding5','Finding6','Finding7','Finding8','Finding9','Finding10','Finding11','Finding12','Finding13','Finding14','Finding20','Finding21','Finding22','Finding23']\n",
    "    for i in range(len(list_92)):\n",
    "        column_name = list_92[i]\n",
    "        column_data = data_clean[column_name]\n",
    "        #print nan indices\n",
    "        indices92 = column_data[column_data == 92].index\n",
    "        data_clean[column_name] = column_data.replace(92, np.nan)\n",
    "        \n",
    "    # change 'other' in column to NaN for the following list of features\n",
    "    list_other = ['Race','EDDisposition']\n",
    "    for i in range(len(list_other)):\n",
    "        column_name = list_other[i]\n",
    "        column_data = data_clean[column_name]\n",
    "        data_clean[column_name] = column_data.replace('other', np.nan)\n",
    "    # remove CTForm1\n",
    "    data_clean = data_clean.drop(columns=['CTForm1'])\n",
    "       \n",
    "    if remove_feats_after_ct:\n",
    "        # Remove features after CT\n",
    "        posCT_index = data_clean.columns.get_loc('CTDone')\n",
    "        data_clean = data_clean.drop(data_clean.columns[posCT_index:data_clean.shape[1]-1], axis=1)\n",
    "        \n",
    "    if remove_TBI_rows_with_nan:\n",
    "        # Remove rows with NaN values in PosIntFinal\n",
    "        data_clean = data_clean.dropna(subset=['PosIntFinal'])\n",
    "    \n",
    "    if rm_feats:\n",
    "        # Remove features with more than threshold percent of missing values\n",
    "        missing_percentage = data_clean.isnull().mean()\n",
    "        missing_columns = missing_percentage[missing_percentage > threshold].index.tolist()\n",
    "        data_clean = data_clean.drop(columns=missing_columns)\n",
    "    \n",
    "    if remove_GCS_total_mismatch:\n",
    "        # remove rows where GCSTotal does not equal the sum of GCS components\n",
    "        data_clean['CalculatedTotal'] = data_clean['GCSEye'] + data_clean['GCSVerbal'] + data_clean['GCSMotor']\n",
    "        data_clean = data_clean[data_clean['CalculatedTotal'] == data_clean['GCSTotal']]\n",
    "        data_clean = data_clean.drop(columns=['CalculatedTotal'])\n",
    "\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e5707d-e804-44d1-83a6-3e77231e120d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PatNum  EmplType  Certification  InjuryMech  High_impact_InjSev  \\\n",
      "0       1       3.0              3        11.0                 2.0   \n",
      "1       2       5.0              3         8.0                 2.0   \n",
      "2       3       5.0              3         5.0                 2.0   \n",
      "3       4       5.0              3         6.0                 1.0   \n",
      "4       5       3.0              3        12.0                 2.0   \n",
      "\n",
      "   Amnesia_verb  LOCSeparate  Seiz  ActNorm  HA_verb  ...  Drugs  AgeInMonth  \\\n",
      "0           0.0          0.0   0.0      1.0      1.0  ...    0.0         197   \n",
      "1           0.0          0.0   0.0      1.0      0.0  ...    0.0          64   \n",
      "2           NaN          NaN   NaN      0.0      NaN  ...    0.0         170   \n",
      "3          91.0          0.0   0.0      1.0     91.0  ...    0.0          13   \n",
      "4          91.0          0.0   0.0      0.0     91.0  ...    0.0          14   \n",
      "\n",
      "   AgeinYears  AgeTwoPlus  Gender  Ethnicity  Race  Observed  EDDisposition  \\\n",
      "0          16           2     1.0        2.0   2.0       0.0            1.0   \n",
      "1           5           2     2.0        2.0   1.0       0.0            1.0   \n",
      "2          14           2     1.0        NaN   1.0       0.0            5.0   \n",
      "3           1           1     2.0        2.0   2.0       0.0            1.0   \n",
      "4           1           1     1.0        2.0   2.0       0.0            1.0   \n",
      "\n",
      "   PosIntFinal  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the cleaning function (assuming clean_data is defined elsewhere)\n",
    "data_clean = clean_data(\"TBI PUD 10-08-2013.csv\")  # Make sure the file path is correct\n",
    "\n",
    "# Save the cleaned DataFrame as a CSV file\n",
    "data_clean_path = \"cleaned_data.csv\"\n",
    "data_clean.to_csv(data_clean_path, index=False)\n",
    "\n",
    "# Read the head of the saved CSV file\n",
    "df = pd.read_csv(data_clean_path)  # Read the saved data back\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44afb74f-9a62-4b3f-bc27-63e783bc9f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 33628 samples\n",
      "Test set size: 8408 samples\n",
      "Original training set class distribution:\n",
      "0.0    33065\n",
      "1.0      563\n",
      "Name: PosIntFinal, dtype: int64\n",
      "Balanced training set size: 66130 samples\n",
      "Balanced training set class distribution:\n",
      "[33065 33065]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load cleaned data\n",
    "dt = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Verify the target column exists\n",
    "target_column = 'PosIntFinal'  # Update to your target column name\n",
    "if target_column not in dt.columns:\n",
    "    raise ValueError(\n",
    "        f\"Target column '{target_column}' not found in dataset. Available columns: {list(dt.columns)}\"\n",
    "    )\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = dt.drop(columns=target_column)\n",
    "y = dt[target_column]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display sizes of train and test sets\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Test set size: {len(X_test)} samples\")\n",
    "\n",
    "# Check original class distribution in training set\n",
    "print(\"Original training set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Handle class imbalance by oversampling the minority class\n",
    "# Combine X_train and y_train into one dataset\n",
    "train_data = np.hstack((X_train, y_train.values.reshape(-1, 1)))\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority = train_data[train_data[:, -1] == 0]  # Assuming class 0 is majority\n",
    "minority = train_data[train_data[:, -1] == 1]  # Assuming class 1 is minority\n",
    "\n",
    "# Oversample the minority class\n",
    "minority_oversampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "\n",
    "# Combine back into a balanced dataset\n",
    "train_balanced = np.vstack((majority, minority_oversampled))\n",
    "np.random.shuffle(train_balanced)  # Shuffle the dataset\n",
    "\n",
    "# Split features and target\n",
    "X_train_balanced = train_balanced[:, :-1]\n",
    "y_train_balanced = train_balanced[:, -1]\n",
    "\n",
    "# Display the size and class distribution of the balanced training set\n",
    "print(f\"Balanced training set size: {len(X_train_balanced)} samples\")\n",
    "print(\"Balanced training set class distribution:\")\n",
    "print(np.bincount(y_train_balanced.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec66a2de-1805-43e2-a3ac-074d9d9d232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     41319\n",
      "         1.0       0.21      0.63      0.31       717\n",
      "\n",
      "    accuracy                           0.95     42036\n",
      "   macro avg       0.60      0.80      0.64     42036\n",
      "weighted avg       0.98      0.95      0.96     42036\n",
      "\n",
      "{'best_params': {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'feature_selection__k': 5}, 'accuracy': 0.95246931201827, 'precision': 0.9799931177214962, 'recall': 0.95246931201827, 'f1_score': 0.9640763660133603, 'roc_auc': 0.8044821049599362, 'false_negative_rate': 0.3668061366806137, 'cross_val_scores': array([0.96329176, 0.96404425, 0.9671322 , 0.96750861, 0.96269169]), 'mean_cv_score': 0.9649337017482589, 'std_cv_score': 0.001998864414177428}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_curve, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate_fnr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the False Negative Rate (FNR).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: False Negative Rate\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fn = cm[1, 0]  # False negatives\n",
    "    tp = cm[1, 1]  # True positives\n",
    "    return fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "\n",
    "def advanced_logistic_regression(dt, target_column):\n",
    "    \"\"\"\n",
    "    Advanced Logistic Regression with comprehensive preprocessing and model evaluation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dt : pandas.DataFrame\n",
    "        Input dataset\n",
    "    target_column : str\n",
    "        Name of the target variable column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: A comprehensive dictionary of model performance metrics and insights\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X = dt.drop(columns=[target_column])\n",
    "    y = dt[target_column]\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', RobustScaler())  # More robust scaling\n",
    "            ]), numeric_features)\n",
    "        ])\n",
    "    \n",
    "    # Full pipeline with feature selection and logistic regression\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=10)),  # Select top 10 features\n",
    "        ('classifier', LogisticRegression(\n",
    "            max_iter=5000,  # Increased max iterations\n",
    "            class_weight='balanced',  # Handle class imbalance\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Hyperparameter tuning grid\n",
    "    param_grid = {\n",
    "        'feature_selection__k': [5, 10, 15],  # Different numbers of top features\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    \n",
    "    # Stratified K-Fold Cross Validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=cv, \n",
    "        scoring='f1',  # Using F1 score for balanced evaluation\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X)\n",
    "    \n",
    "    # Probability for the positive class\n",
    "    y_proba = best_model.predict_proba(X)[:, 1]  # Probabilities for the positive class\n",
    "    \n",
    "    # Performance Metrics\n",
    "    performance_metrics = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy_score(y, y_pred),\n",
    "        'precision': precision_score(y, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y, y_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y, y_proba),  # Using probabilities for AUC\n",
    "        'false_negative_rate': evaluate_fnr(y, y_pred)  # False Negative Rate\n",
    "    }\n",
    "    \n",
    "    # Learning Curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        best_model, X, y, \n",
    "        cv=cv, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "    \n",
    "    # Visualization of Learning Curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "    plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Training Examples')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='f1_weighted')\n",
    "    \n",
    "    # Additional insights\n",
    "    performance_metrics.update({\n",
    "        'cross_val_scores': cv_scores,\n",
    "        'mean_cv_score': np.mean(cv_scores),\n",
    "        'std_cv_score': np.std(cv_scores)\n",
    "    })\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    return performance_metrics, y_proba\n",
    "\n",
    "# Usage example (uncomment and modify as needed)\n",
    "results, probabilities = advanced_logistic_regression(dt, 'PosIntFinal')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8518f50-c41a-49e9-a44a-64842844fcd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative Rate: 0.3668061366806137\n"
     ]
    }
   ],
   "source": [
    "print(\"False Negative Rate:\", results['false_negative_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b954fdf3-141c-4717-9526-26ba60546c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Save the Probabilities model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a preprocessing pipeline to handle missing values and scaling\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Replace NaNs with median of each column\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# Preprocess the training data\n",
    "X_train_balanced_cleaned = preprocessing_pipeline.fit_transform(X_train_balanced)\n",
    "y_train_balanced_cleaned = y_train_balanced\n",
    "\n",
    "# Preprocess the test data using the same transformations\n",
    "X_test_cleaned = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the preprocessed training data\n",
    "logreg_model.fit(X_train_balanced_cleaned, y_train_balanced_cleaned)\n",
    "\n",
    "# Predictions for Logistic Regression\n",
    "y_pred_logreg = logreg_model.predict(X_test_cleaned)\n",
    "y_proba_logreg = logreg_model.predict_proba(X_test_cleaned)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Save the model probabilities\n",
    "np.save('logreg.npy', y_proba_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbc565-f67e-439f-9a92-75d3ecf2e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_test = test_df[\"PosIntFinal\"]\n",
    "X_test = test_df.drop(columns=[\"PosIntFinal\"])\n",
    "\n",
    "y_test_prob = model.predict(X_test)\n",
    "\n",
    "y_test_pred = (y_test_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Step 3: Calculate recall\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(f\"Recall for the test set: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
