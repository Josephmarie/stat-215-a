{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fe2c19-0d81-4ce1-a4ac-fcf0256a59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, matplotlib, seaborn\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/accounts/class/s215a/joseph.kouadio/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.7 matplotlib-3.9.4 pyparsing-3.2.0 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245139e8-ac62-4b17-a2c6-ca2f098519f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ddb6cad-4d74-468f-b9c9-8285e6c2d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/linux/miniforge-3.12/envs/jupyterhub-5.x/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78e974ed-1718-4383-abda-feb0c4e9a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative Rate: 0.16883116883116883\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.94      8254\n",
      "         1.0       0.13      0.83      0.23       154\n",
      "\n",
      "    accuracy                           0.90      8408\n",
      "   macro avg       0.56      0.86      0.58      8408\n",
      "weighted avg       0.98      0.90      0.93      8408\n",
      "\n",
      "Performance Metrics: {'accuracy': 0.8952188392007612, 'precision': 0.9806315418250473, 'recall': 0.8952188392007612, 'f1_score': 0.9306473629044654, 'roc_auc': np.float64(0.9462370074800412), 'false_negative_rate': np.float64(0.16883116883116883), 'cross_val_scores': array([0.89467051, 0.88695431, 0.88786137, 0.89050344, 0.89157023]), 'mean_cv_score': np.float64(0.890311974474478), 'std_cv_score': np.float64(0.0027530368782404347)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_auc_score\n",
    ")\n",
    "import joblib  # For saving the model\n",
    "\n",
    "def evaluate_fnr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the False Negative Rate (FNR).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: False Negative Rate\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fn = cm[1, 0]  # False negatives\n",
    "    tp = cm[1, 1]  # True positives\n",
    "    return fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "\n",
    "def advanced_logistic_regression_perturbed(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Advanced Logistic Regression with perturbation analysis and model evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : array-like\n",
    "        Training data features\n",
    "    y_train : array-like\n",
    "        Training data labels\n",
    "    X_test : array-like\n",
    "        Test data features\n",
    "    y_test : array-like\n",
    "        Test data labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: A comprehensive dictionary of model performance metrics and insights\n",
    "    \"\"\"\n",
    "    # Create preprocessing pipeline to handle missing values and scaling\n",
    "    preprocessing_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),  # Replace NaNs with median of each column\n",
    "        ('scaler', StandardScaler())  # Scale the features\n",
    "    ])\n",
    "    \n",
    "    # Preprocess the training data (perturbed)\n",
    "    X_train_cleaned = preprocessing_pipeline.fit_transform(X_train)\n",
    "    y_train_cleaned = y_train\n",
    "\n",
    "    # Preprocess the test data using the same transformations\n",
    "    X_test_cleaned = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "    # Full pipeline with logistic regression\n",
    "    model = LogisticRegression(max_iter=5000, class_weight='balanced', random_state=42)\n",
    "    \n",
    "    # Fit the model on the preprocessed training data\n",
    "    model.fit(X_train_cleaned, y_train_cleaned)\n",
    "    \n",
    "    # Predictions for Logistic Regression\n",
    "    y_pred = model.predict(X_test_cleaned)\n",
    "    y_proba = model.predict_proba(X_test_cleaned)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "    # Performance metrics\n",
    "    performance_metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba),  # Using probabilities for AUC\n",
    "        'false_negative_rate': evaluate_fnr(y_test, y_pred)  # False Negative Rate\n",
    "    }\n",
    "\n",
    "    # Print False Negative Rate\n",
    "    print(\"False Negative Rate:\", performance_metrics['false_negative_rate'])\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_perturbed.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train_cleaned, y_train_cleaned, cv=cv, scoring='f1_weighted')\n",
    "\n",
    "    # Additional insights\n",
    "    performance_metrics.update({\n",
    "        'cross_val_scores': cv_scores,\n",
    "        'mean_cv_score': np.mean(cv_scores),\n",
    "        'std_cv_score': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Print detailed classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Learning Curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X_train_cleaned, y_train_cleaned, \n",
    "        cv=cv, train_sizes=np.linspace(0.1, 1.0, 10), \n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "\n",
    "    # Visualization of Learning Curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "    plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Training Examples')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curve_perturbed.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model probabilities\n",
    "    np.save('logreg_perturbed_probabilities.npy', y_proba)\n",
    "\n",
    "    # Optionally, save the model itself\n",
    "    joblib.dump(model, 'logreg_model_perturbed.pkl')\n",
    "    \n",
    "    return performance_metrics, y_proba\n",
    "\n",
    "# Load your perturbed data\n",
    "X_train_perturbed = np.load('X_train_balanced_pertubed.npy')\n",
    "y_train_perturbed = np.load('y_train_balanced_pertubed.npy')\n",
    "X_test_perturbed = np.load('X_test_pertubed.npy')\n",
    "y_test_perturbed = np.load('y_test_pertubed.npy')\n",
    "\n",
    "# Call the function with the perturbed data\n",
    "results, probabilities = advanced_logistic_regression_perturbed(\n",
    "    X_train_perturbed, y_train_perturbed, X_test_perturbed, y_test_perturbed\n",
    ")\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Performance Metrics:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
